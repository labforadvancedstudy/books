# isaac_asimov_laws
@HA_science_fiction @robot_ethics @AI_safety @three_laws
2025-06-24

Asimov's Three Laws of Robotics (1942) remain the most cited framework in AI ethics - 80 years later.
Written for pulp magazines, now discussed at UN panels on autonomous weapons.

The Laws:
1. A robot may not injure a human or through inaction allow harm
2. A robot must obey human orders except where they conflict with First Law
3. A robot must protect itself except where it conflicts with First or Second Laws

Later added Zeroth Law: protect humanity even if individuals must be harmed.
Every story explored edge cases - the laws' failure modes were the point.
"Runaround": circular logic paralysis. "Liar!": kindness as cruelty.
"The Evitable Conflict": machines controlling economy to "protect" humanity.

Modern relevance is uncanny:
- Tesla autopilot: trolley problems at 70mph
- Military drones: human-in-the-loop as Second Law worship
- AI alignment: how to encode "harm" when humans disagree
- AGI safety: Zeroth Law as existential risk

Asimov assumed we'd hard-code ethics. Instead we train neural networks and pray.
His robots were moral agents struggling with contradictions - like humans but honest about it.
The Laws' real insight: perfect safety is impossible when serving imperfect beings.
Every AI safety paper footnotes Asimov - science fiction as ethical foundation.