# 레벨 5.5: 서버 인프라 실무 - "백엔드 없이 VoIP는 없다"

*2024년 7월. 서비스 다운 사고 포스트모텀.*

DevOps: "시그널링 서버가 죽었는데 왜 모니터링이 안 됐죠?"
나: "Health check는 정상이었는데..."
DevOps: "WebSocket 연결은 체크 안 했네요?"
나: (아... 진짜 상태 체크를 안 했구나)

## Rust 시그널링 서버 구축

### 왜 Rust인가?

```rust
// Rust 선택 이유
/*
1. 메모리 안정성: Segfault 없음
2. 성능: C++ 수준, GC 없음
3. 동시성: Fearless Concurrency
4. 생태계: Tokio, Actix 등 성숙
5. 실제 사례: Discord, Cloudflare가 사용
*/

use tokio::net::{TcpListener, TcpStream};
use tokio_tungstenite::{accept_async, WebSocketStream};
use futures_util::{StreamExt, SinkExt};
use std::sync::Arc;
use dashmap::DashMap;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone)]
struct Client {
    id: String,
    ws: Arc<Mutex<WebSocketStream<TcpStream>>>,
    room_id: Option<String>,
    metadata: ClientMetadata,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ClientMetadata {
    user_agent: String,
    ip_address: String,
    connected_at: chrono::DateTime<chrono::Utc>,
    last_ping: chrono::DateTime<chrono::Utc>,
}

// 고성능 시그널링 서버
struct SignalingServer {
    clients: Arc<DashMap<String, Client>>,
    rooms: Arc<DashMap<String, Vec<String>>>,
    metrics: Arc<Metrics>,
}

impl SignalingServer {
    async fn run(&self, addr: &str) -> Result<(), Box<dyn std::error::Error>> {
        let listener = TcpListener::bind(addr).await?;
        println!("시그널링 서버 시작: {}", addr);
        
        // Prometheus 메트릭 엔드포인트
        tokio::spawn(self.run_metrics_server());
        
        while let Ok((stream, addr)) = listener.accept().await {
            // 연결당 태스크 생성
            tokio::spawn(self.handle_connection(stream, addr));
        }
        
        Ok(())
    }
    
    async fn handle_connection(
        &self,
        stream: TcpStream,
        addr: std::net::SocketAddr
    ) {
        // WebSocket 업그레이드
        let ws_stream = match accept_async(stream).await {
            Ok(ws) => ws,
            Err(e) => {
                eprintln!("WebSocket 핸드셰이크 실패: {}", e);
                return;
            }
        };
        
        let client_id = uuid::Uuid::new_v4().to_string();
        let (tx, rx) = ws_stream.split();
        
        // 클라이언트 등록
        let client = Client {
            id: client_id.clone(),
            ws: Arc::new(Mutex::new(tx)),
            room_id: None,
            metadata: ClientMetadata {
                user_agent: String::new(),
                ip_address: addr.to_string(),
                connected_at: chrono::Utc::now(),
                last_ping: chrono::Utc::now(),
            },
        };
        
        self.clients.insert(client_id.clone(), client);
        self.metrics.active_connections.inc();
        
        // 메시지 처리 루프
        self.message_loop(client_id, rx).await;
    }
    
    async fn message_loop(
        &self,
        client_id: String,
        mut rx: impl StreamExt<Item = Result<Message, Error>>
    ) {
        while let Some(msg) = rx.next().await {
            match msg {
                Ok(Message::Text(text)) => {
                    if let Ok(signal) = serde_json::from_str::<SignalingMessage>(&text) {
                        self.handle_signaling(client_id.clone(), signal).await;
                    }
                }
                Ok(Message::Ping(payload)) => {
                    // Pong 응답
                    if let Some(client) = self.clients.get_mut(&client_id) {
                        client.metadata.last_ping = chrono::Utc::now();
                        let _ = client.ws.lock().await.send(Message::Pong(payload)).await;
                    }
                }
                Ok(Message::Close(_)) => break,
                Err(e) => {
                    eprintln!("WebSocket 에러: {}", e);
                    break;
                }
                _ => {}
            }
        }
        
        // 클라이언트 정리
        self.cleanup_client(&client_id).await;
    }
}

#[derive(Debug, Serialize, Deserialize)]
#[serde(tag = "type")]
enum SignalingMessage {
    Join { room_id: String },
    Leave { room_id: String },
    Offer { to: String, sdp: String },
    Answer { to: String, sdp: String },
    IceCandidate { to: String, candidate: String },
}
```

### 스케일링 전략

```rust
// 수평 확장을 위한 Redis Pub/Sub
use redis::aio::ConnectionManager;
use redis::AsyncCommands;

struct ScalableSignalingServer {
    local_clients: Arc<DashMap<String, Client>>,
    redis: ConnectionManager,
    server_id: String,
}

impl ScalableSignalingServer {
    async fn handle_signaling(&self, from: String, msg: SignalingMessage) {
        match msg {
            SignalingMessage::Offer { to, sdp } => {
                // 로컬 클라이언트 확인
                if let Some(client) = self.local_clients.get(&to) {
                    // 직접 전달
                    self.send_to_client(client, msg).await;
                } else {
                    // Redis를 통해 다른 서버로 전달
                    let payload = serde_json::to_string(&msg).unwrap();
                    self.redis.publish::<_, _, ()>(
                        format!("signaling:{}", to),
                        payload
                    ).await.unwrap();
                }
            }
            _ => {}
        }
    }
    
    async fn subscribe_to_redis(&self) {
        let mut pubsub = self.redis.get_async_connection().await.unwrap();
        pubsub.subscribe(format!("signaling:*")).await.unwrap();
        
        while let Some(msg) = pubsub.on_message().next().await {
            let payload: String = msg.get_payload().unwrap();
            if let Ok(signal) = serde_json::from_str::<SignalingMessage>(&payload) {
                // 로컬 클라이언트에게 전달
                self.route_message(signal).await;
            }
        }
    }
}

// 로드 밸런싱 (Nginx 설정)
/*
upstream signaling_servers {
    ip_hash;  # 같은 클라이언트는 같은 서버로
    server signaling1.example.com:8080;
    server signaling2.example.com:8080;
    server signaling3.example.com:8080;
}

server {
    listen 443 ssl http2;
    
    location /ws {
        proxy_pass http://signaling_servers;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header X-Real-IP $remote_addr;
        proxy_read_timeout 86400;
    }
}
*/
```

## TURN 서버 구축과 운영

```rust
// coturn 설정 (turnserver.conf)
/*
# 네트워크 설정
listening-port=3478
tls-listening-port=5349
external-ip=1.2.3.4/10.0.0.1

# 인증
use-auth-secret
static-auth-secret=your-secret-key

# 릴레이 설정
relay-ip=10.0.0.1
min-port=49152
max-port=65535

# 대역폭 제한
max-bps=1000000  # 1Mbps per user
total-quota=1000  # 1GB per user

# 로깅
log-file=/var/log/turn.log
verbose
*/

// TURN 서버 모니터링
struct TurnMonitor {
    coturn_stats: Arc<Mutex<CoturnStats>>,
}

impl TurnMonitor {
    async fn collect_metrics(&self) {
        loop {
            // turnadmin 명령으로 통계 수집
            let output = Command::new("turnadmin")
                .args(&["-k", "-l"])
                .output()
                .await
                .unwrap();
            
            let stats = self.parse_stats(output.stdout);
            
            // Prometheus 메트릭 업데이트
            TURN_ACTIVE_SESSIONS.set(stats.active_sessions as f64);
            TURN_BANDWIDTH_USAGE.set(stats.bandwidth_mbps);
            TURN_PACKET_RATE.set(stats.packets_per_second);
            
            // 임계값 체크
            if stats.bandwidth_mbps > 800.0 {
                self.alert("TURN 서버 대역폭 80% 초과").await;
            }
            
            tokio::time::sleep(Duration::from_secs(10)).await;
        }
    }
}
```

## Kubernetes 배포

```yaml
# signaling-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: signaling-server
  namespace: voip
spec:
  replicas: 3
  selector:
    matchLabels:
      app: signaling
  template:
    metadata:
      labels:
        app: signaling
    spec:
      containers:
      - name: signaling
        image: your-registry/signaling-server:latest
        ports:
        - containerPort: 8080
          name: websocket
        - containerPort: 9090
          name: metrics
        env:
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: redis-secret
              key: url
        - name: SERVER_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 9090
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 9090
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: signaling-service
  namespace: voip
spec:
  selector:
    app: signaling
  ports:
  - port: 80
    targetPort: 8080
    name: websocket
  type: LoadBalancer
  sessionAffinity: ClientIP  # Sticky sessions
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: signaling-hpa
  namespace: voip
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: signaling-server
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Pods
    pods:
      metric:
        name: websocket_connections
      target:
        type: AverageValue
        averageValue: "1000"
```

### Helm Chart

```yaml
# values.yaml
signaling:
  replicaCount: 3
  image:
    repository: your-registry/signaling-server
    tag: "1.0.0"
    pullPolicy: IfNotPresent
  
  resources:
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1Gi"
      cpu: "1000m"
  
  autoscaling:
    enabled: true
    minReplicas: 3
    maxReplicas: 20
    targetCPU: 70
    targetConnections: 1000

turn:
  enabled: true
  servers:
    - host: turn1.example.com
      port: 3478
      secret: "your-secret"
    - host: turn2.example.com
      port: 3478
      secret: "your-secret"

redis:
  enabled: true
  auth:
    enabled: true
    password: "redis-password"
  cluster:
    enabled: true
    nodes: 3

monitoring:
  prometheus:
    enabled: true
    serviceMonitor:
      enabled: true
  grafana:
    enabled: true
    dashboards:
      enabled: true
```

## 모니터링과 알림

```yaml
# prometheus-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: voip-alerts
  namespace: voip
spec:
  groups:
  - name: signaling
    interval: 30s
    rules:
    - alert: HighWebSocketConnections
      expr: websocket_connections > 5000
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High WebSocket connections"
        description: "{{ $labels.instance }} has {{ $value }} connections"
    
    - alert: SignalingServerDown
      expr: up{job="signaling"} == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "Signaling server is down"
        description: "{{ $labels.instance }} is down"
    
    - alert: HighErrorRate
      expr: rate(signaling_errors_total[5m]) > 10
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High error rate"
        description: "Error rate is {{ $value }} errors/sec"
  
  - name: turn
    interval: 30s
    rules:
    - alert: TurnBandwidthHigh
      expr: turn_bandwidth_mbps > 800
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "TURN bandwidth usage high"
        description: "TURN server using {{ $value }}Mbps"
    
    - alert: TurnSessionsHigh
      expr: turn_active_sessions > 1000
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Too many TURN sessions"
        description: "{{ $value }} active TURN sessions"
```

### Grafana 대시보드

```json
{
  "dashboard": {
    "title": "VoIP Infrastructure",
    "panels": [
      {
        "title": "Active Connections",
        "targets": [
          {
            "expr": "sum(websocket_connections)",
            "legendFormat": "Total Connections"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Message Rate",
        "targets": [
          {
            "expr": "rate(signaling_messages_total[1m])",
            "legendFormat": "Messages/sec"
          }
        ],
        "type": "graph"
      },
      {
        "title": "TURN Bandwidth",
        "targets": [
          {
            "expr": "turn_bandwidth_mbps",
            "legendFormat": "Bandwidth (Mbps)"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Error Rate",
        "targets": [
          {
            "expr": "rate(signaling_errors_total[5m])",
            "legendFormat": "Errors/sec"
          }
        ],
        "type": "graph"
      }
    ]
  }
}
```

## 실제 운영 노하우

### 1. 무중단 배포

```bash
#!/bin/bash
# Blue-Green 배포 스크립트

# 1. 새 버전 배포 (Green)
kubectl apply -f signaling-deployment-green.yaml

# 2. Health check
for i in {1..30}; do
  if kubectl get pods -l version=green | grep -q "Running"; then
    echo "Green deployment ready"
    break
  fi
  sleep 10
done

# 3. 트래픽 전환
kubectl patch service signaling-service -p '{"spec":{"selector":{"version":"green"}}}'

# 4. 모니터링 (5분)
sleep 300

# 5. 이상 없으면 Blue 제거
kubectl delete deployment signaling-deployment-blue
```

### 2. 디버깅 도구

```rust
// 실시간 디버깅 엔드포인트
impl SignalingServer {
    async fn debug_endpoint(&self) -> impl warp::Reply {
        let stats = json!({
            "active_connections": self.clients.len(),
            "rooms": self.rooms.len(),
            "memory_usage": self.get_memory_usage(),
            "cpu_usage": self.get_cpu_usage(),
            "message_rate": self.metrics.message_rate(),
            "error_rate": self.metrics.error_rate(),
            "uptime": self.uptime.elapsed().as_secs(),
        });
        
        warp::reply::json(&stats)
    }
    
    async fn trace_client(&self, client_id: String) -> impl warp::Reply {
        // 특정 클라이언트의 모든 활동 추적
        let trace = self.client_traces.get(&client_id);
        warp::reply::json(&trace)
    }
}
```

### 3. 비용 최적화

```python
# AWS 비용 계산 스크립트
def calculate_monthly_cost(users, avg_call_duration, calls_per_day):
    # EC2 (시그널링 서버)
    ec2_instances = max(3, users // 5000)  # 5000 users per instance
    ec2_cost = ec2_instances * 60  # t3.large = $60/month
    
    # TURN 서버
    turn_instances = max(2, users // 10000)
    turn_cost = turn_instances * 60
    
    # 대역폭 (TURN relay 10% 가정)
    relay_users = users * 0.1
    bandwidth_gb = (relay_users * avg_call_duration * calls_per_day * 30 * 50) / 1024  # 50KB/s
    bandwidth_cost = bandwidth_gb * 0.09  # $0.09/GB
    
    # RDS (메타데이터)
    rds_cost = 100  # db.t3.medium
    
    # CloudWatch
    cloudwatch_cost = 50
    
    total = ec2_cost + turn_cost + bandwidth_cost + rds_cost + cloudwatch_cost
    
    print(f"""
    월간 비용 계산 ({users} 사용자):
    - EC2 (시그널링): ${ec2_cost}
    - TURN 서버: ${turn_cost}
    - 대역폭: ${bandwidth_cost:.2f}
    - RDS: ${rds_cost}
    - CloudWatch: ${cloudwatch_cost}
    
    총계: ${total:.2f}/월
    사용자당: ${total/users:.3f}/월
    """)
    
    return total

# 예시: 10,000명, 평균 5분 통화, 하루 2회
calculate_monthly_cost(10000, 300, 2)
```

## 장애 대응 시나리오

### 시나리오 1: 시그널링 서버 다운

```bash
# 즉시 대응 절차
1. kubectl get pods -n voip  # 상태 확인
2. kubectl logs -n voip signaling-xxx  # 로그 확인
3. kubectl rollout restart deployment/signaling-server  # 재시작
4. kubectl scale deployment/signaling-server --replicas=5  # 스케일 업

# 근본 원인 분석
kubectl describe pod signaling-xxx
kubectl top pods -n voip
kubectl get events -n voip
```

### 시나리오 2: TURN 서버 과부하

```python
# 자동 스케일링 스크립트
import boto3
import time

def auto_scale_turn():
    cloudwatch = boto3.client('cloudwatch')
    ec2 = boto3.client('ec2')
    
    # 메트릭 확인
    response = cloudwatch.get_metric_statistics(
        Namespace='TURN',
        MetricName='BandwidthUtilization',
        Statistics=['Average'],
        Period=300,
        StartTime=time.time() - 600,
        EndTime=time.time()
    )
    
    avg_utilization = response['Datapoints'][0]['Average']
    
    if avg_utilization > 80:
        # 새 TURN 서버 시작
        ec2.run_instances(
            ImageId='ami-turn-server',
            InstanceType='t3.large',
            MinCount=1,
            MaxCount=1,
            UserData='''#!/bin/bash
            docker run -d coturn/coturn
            '''
        )
        print("새 TURN 서버 시작됨")
```

## 다음 레벨 예고

레벨 6.5에서는 법적 이슈와 컴플라이언스:
- GDPR 대응
- 통화 녹음 법규
- 개인정보 보호
- 각국 규제 대응

"기술만으로는 서비스를 못 한다"